# Transfer Learning

Everything is in comments

## Specify Model

```python

from tensorflow.python.keras.applications import ResNet50
from tensorflow.python.keras.models import Sequential  # we'll have a model that is sequence of layers
from tensorflow.python.keras.layers import Dense, Flatten, GlobalAveragePooling2D  # Dense layer 

num_classes = 2 # number of classes we want to distinguish in last layer, rural and urban in this case
resnet_weights_path = '../input/resnet50/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5'   

my_new_model = Sequential()
my_new_model.add(ResNet50(include_top=False, pooling='avg', weights=resnet_weights_path)) # We add the layers of ResNet except for the top layer that makes predictions
                                                                                          # pooling avg means to convert the second last layer in a vector if it is a higher dimension tensor by averaging.

my_new_model.add(Dense(num_classes, activation='softmax')) # softmax converts raw numbers to probability 

# Say not to train first layer (ResNet) model. It is already trained
my_new_model.layers[0].trainable = False # So basically we have two layers, one is ResNet(which has lot of layers inside it) and other is Dense, which we want to train.

```

## Compile Model

```python
# sgd = stochastic gradient descent for minimising loss function
# compiled command tells tensorflow how to update relationships in dense connections, when we're doing the training with our Data.
# accuracy is what we want to measure, it's just converting loss into a more readable format.
my_new_model.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy']) 

```

## Fit Model

```python

from tensorflow.python.keras.applications.resnet50 import preprocess_input
from tensorflow.python.keras.preprocessing.image import ImageDataGenerator

image_size = 224
data_generator = ImageDataGenerator(preprocessing_function=preprocess_input)  # takes image and preprocesses it fro use in model


train_generator = data_generator.flow_from_directory(      # batch size means 24 photos will be taken in at once for training at a time
        '../input/urban-and-rural-photos/rural_and_urban_photos/train',
        target_size=(image_size, image_size),
        batch_size=24,
        class_mode='categorical')   # categorical class mode means division in classes would be performed

validation_generator = data_generator.flow_from_directory(                
        '../input/urban-and-rural-photos/rural_and_urban_photos/val',
        target_size=(image_size, image_size),
        class_mode='categorical')

my_new_model.fit_generator(
        train_generator,
        steps_per_epoch=3,    # 3 iterations for training data
        validation_data=validation_generator, 
        validation_steps=1)   # 1 iteration for prediction of traing data
        
        
        
 output - 
 
Found 72 images belonging to 2 classes.
Found 20 images belonging to 2 classes.
Epoch 1/1
3/3 [==============================] - 21s 7s/step - loss: 0.5654 - acc: 0.7361 - val_loss: 0.4350 - val_acc: 0.8500
<tensorflow.python.keras.callbacks.History at 0x7f5f8793fb70>
        
        
       
```

Accuracy of trained data comes out to be less than validation data because while training, it was cumulatively calculated after each iteration while the model was still learning. For validation data, model was fully prepared afterwards.































